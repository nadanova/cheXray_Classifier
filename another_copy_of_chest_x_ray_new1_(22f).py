# -*- coding: utf-8 -*-
"""Another copy of Chest_x_Ray_new1_(22f).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GPAGajvkVTsr0kjwbctku-eMSs8M3BXs
"""

!pip install kaggle

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

pd.options.display.max_colwidth= 100

import random
import os


from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report


from tensorflow.keras.models import Sequential
from tensorflow.keras import layers


from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import optimizers
from tensorflow.keras import applications
from tensorflow.keras.backend import clear_session
from tensorflow.keras import Model

import shutil
# import warnings
# warnings.filterwarnings("ignore")

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia

!unzip /content/chest-xray-pneumonia.zip





#number of image in each folder
print(len(os.listdir('/content/chest_xray/train/NORMAL')))
print(len(os.listdir('/content/chest_xray/train/PNEUMONIA')))

print(len(os.listdir('/content/chest_xray/test/NORMAL')))
print(len(os.listdir('/content/chest_xray/test/PNEUMONIA')))

print(len(os.listdir('/content/chest_xray/val/NORMAL')))
print(len(os.listdir('/content/chest_xray/val/PNEUMONIA')))

# Data Preprocessing

train='/content/chest_xray/train'
val='/content/chest_xray/test'
test='/content/chest_xray/val'

# List to store image file paths
train_data_images = []

# Traverse through subdirectories in the source directory
for root, dirs, files in os.walk(train):
    for file in files:
        if file.endswith(('.jpg', '.jpeg', '.png')):  # Filter image files
            # Get the full path of each image file
            file_path = os.path.join(root, file)
            train_data_images.append(file_path)

val_data_images = []

# Traverse through subdirectories in the source directory
for root, dirs, files in os.walk(val):
    for file in files:
        if file.endswith(('.jpg', '.jpeg', '.png')):  # Filter image files
            # Get the full path of each image file
            file_path = os.path.join(root, file)
            val_data_images.append(file_path)

test_data_images = []

# Traverse through subdirectories in the source directory
for root, dirs, files in os.walk(test):
    for file in files:
        if file.endswith(('.jpg', '.jpeg', '.png')):  # Filter image files
            # Get the full path of each image file
            file_path = os.path.join(root, file)
            test_data_images.append(file_path)

# Shuffle the image paths list
random.shuffle(train_data_images)
random.shuffle(test_data_images)
random.shuffle(val_data_images)

#lenght of train
print(len(train_data_images))
print(len(test_data_images))
print(len(val_data_images))

train_data_images[:50]

train_data='/content/chest_xray/train'
val_data='/content/chest_xray/test'
test_data='/content/chest_xray/val'

img_size=(224,224)
batch_size=32

# Data augmentation for training set
train_datagen = ImageDataGenerator(
    rescale=1./255,  # Normalize pixel values to [0,1]
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

test_datagen = ImageDataGenerator(rescale=1./255)
Val_datagen = ImageDataGenerator(rescale=1./255)


# Load the images and labels from the directories
train_generator = train_datagen.flow_from_directory(
    train_data,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary'
)

val_generator = Val_datagen.flow_from_directory(
    val_data,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary'
)

test_generator = test_datagen.flow_from_directory(
    test_data,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary'
)

# #make folder called train_data
os.mkdir('/content/train_data')
os.mkdir('/content/val_data')
os.mkdir('/content/test_data')

print(train_data)

# Ensure the destination folder exists, if not, create it
os.makedirs(train_data, exist_ok=True)

# Loop over each image in the list and copy it to the destination folder
for image in train_data_images:
    if os.path.exists(image):  # Check if the image file exists in the current directory
        shutil.copy(image, train_data)
        print(f"Copied {image} to {train_data}")
    else:
        print(f"Image {image} not found!")

# List the files in the destination folder to verify
print("Files in train_data folder:", os.listdir(train_data))

len(os.listdir(train_data))

# Ensure the destination folder exists, if not, create it
os.makedirs(val_data, exist_ok=True)

# Loop over each image in the list and copy it to the destination folder
for image in val_data_images:
    if os.path.exists(image):  # Check if the image file exists in the current directory
        shutil.copy(image, val_data)
        print(f"Copied {image} to {val_data}")
    else:
        print(f"Image {image} not found!")

# List the files in the destination folder to verify
print("Files in train_data folder:", os.listdir(val_data))

# Ensure the destination folder exists, if not, create it
os.makedirs(test_data, exist_ok=True)

# Loop over each image in the list and copy it to the destination folder
for image in test_data_images:
    if os.path.exists(image):  # Check if the image file exists in the current directory
        shutil.copy(image, test_data)
        print(f"Copied {image} to {test_data}")
    else:
        print(f"Image {image} not found!")

# List the files in the destination folder to verify
print("Files in train_data folder:", os.listdir(test_data))

print(len(train_data_images))
print(len(val_data_images))
print(len(test_data_images))

train_data

#train_data[:50]
len(os.listdir(train_data))

import matplotlib.pyplot as plt

def plot_images(generator,title):
    x,y=next(generator)
    fig , axes =plt.subplots(1,3,figsize=(10,3))
    fig.suptitle(title,fontsize=12)
    for i in range(3):
        axes[i].imshow(x[i])
        axes[i].axis('off')
    plt.show()
plot_images(train_generator ,'Train images')
plot_images(test_generator ,'test images')
plot_images(val_generator ,'Validation images')

"""#Building Model"""

from tensorflow.keras.callbacks import ModelCheckpoint

model_checkpoint_callback = ModelCheckpoint(
    filepath='CNN.weights.h5',
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True
)

Early_Stopping=EarlyStopping(monitor='val_loss',patience=5)
reduce_lr=ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.2,min_lr=0.00005)

IMG_SIZE=224

def get_model():

    #Input shape = [width, height, color channels]
    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))

    # Block One
    x = layers.Conv2D(filters=16, kernel_size=3, padding='valid')(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('relu')(x)
    x = layers.MaxPool2D()(x)
    x = layers.Dropout(0.2)(x)

    # Block Two
    x = layers.Conv2D(filters=32, kernel_size=3, padding='valid')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('relu')(x)
    x = layers.MaxPool2D()(x)
    x = layers.Dropout(0.2)(x)

    # Block Three
    x = layers.Conv2D(filters=64, kernel_size=3, padding='valid')(x)
    x = layers.Conv2D(filters=64, kernel_size=3, padding='valid')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('relu')(x)
    x = layers.MaxPool2D()(x)
    x = layers.Dropout(0.4)(x)

    # Head
    #x = layers.BatchNormalization()(x)
    x = layers.Flatten()(x)
    x = layers.Dense(64, activation='relu')(x)
    x = layers.Dropout(0.5)(x)

    #Final Layer (Output)
    output = layers.Dense(1, activation='sigmoid')(x)

    model = Model(inputs=[inputs], outputs=output)

    return model

# img_L=224

# model=Sequential([
#     layers.Conv2D(32,(3,3),activation='relu', input_shape=(img_L, img_L,3)),
#     layers.MaxPool2D((2,2)),

#     layers.Conv2D(64,(3,3),activation='relu'),
#     layers.MaxPool2D((2,2)),

#     layers.Conv2D(128,(3,3),activation='relu'),
#     layers.MaxPool2D((2,2)),

#     layers.Flatten(),

#     layers.Dense(128,activation='relu'),

#     layers.Dense(1,activation='sigmoid')

# ])

model_get=get_model()
model_get.compile(loss='binary_crossentropy'
              , optimizer =optimizers.Adam(learning_rate=5e-5), metrics=['binary_accuracy'])

model_get.summary()



# history_get=model_get.fit(
#     train_generator,
#     epochs=20,
#     validation_data=val_generator,
#     callbacks=[model_checkpoint_callback,Early_Stopping,reduce_lr]
# )

# model.compile(
#     optimizer='adam',
#     loss='binary_crossentropy',
#     metrics=['accuracy']
# )

model_get.summary()

history=model_get.fit(
    train_generator,
    epochs=30,
    validation_data=test_generator,
    callbacks=[model_checkpoint_callback,Early_Stopping,reduce_lr]
)

"""Transfer learning"""

img_L=224
base_model = applications.ResNet152V2(
    weights='imagenet',
    input_shape=(img_L, img_L, 3),
    include_top=False)

from tensorflow.keras import layers, Model

img_L=224
base_model.trainable = False
def Pre_trained_model():
    # Input shape = [width, height, color channels]
    inputs = layers.Input(shape=(img_L, img_L, 3))

    # Base model
    x = base_model(inputs, training=False)

    # Head
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dense(128, activation='relu')(x)

    # Adding Batch Normalization
    x = layers.BatchNormalization()(x)

    # Increase Dropout to 0.3
    x = layers.Dropout(0.4)(x) ##0.5 perfect

    # Final Layer (Output)
    output = layers.Dense(1, activation='sigmoid')(x)

    model = Model(inputs=[inputs], outputs=output)

    return model

# # Clear my sections
# clear_session()

model_pretrained = Pre_trained_model()
model_pretrained.compile(loss='binary_crossentropy'
              , optimizer =optimizers.Adam(learning_rate=5e-5), metrics=['binary_accuracy'])

model_pretrained.summary()

##1 perfect
history_pretrained=model_pretrained.fit(
    train_generator,
    epochs=20,
    validation_data=val_generator,
    callbacks=[model_checkpoint_callback,Early_Stopping,reduce_lr]
)

##2
history_pretrained=model_pretrained.fit(
    train_generator,
    epochs=20,
    validation_data=val_generator,
    callbacks=[model_checkpoint_callback,Early_Stopping,reduce_lr]
)

# fig,ax = plt.subplots(1,2,figsize=(10,5))
# sns.lineplot(x=history_pretrained.epoch,y=history_pretrained.history['binary_accuracy'],ax=ax[0],label='train')
# sns.lineplot(x=history_pretrained.epoch,y=history_pretrained.history['val_binary_accuracy'],ax=ax[0],label='val')
# ax[0].set_title('Learning Curve(loss)')
# ax[0].set_xlabel('Epochs')
# ax[0].set_ylabel('Accuracy')
# ax[0].legend(['train','Validation'], loc='best')
# plt.show()

fig,ax = plt.subplots(1,2,figsize=(10,5))
sns.lineplot(x=history_pretrained.epoch,y=history_pretrained.history['binary_accuracy'],ax=ax[0],label='train')
sns.lineplot(x=history_pretrained.epoch,y=history_pretrained.history['val_binary_accuracy'],ax=ax[0],label='val')
ax[0].set_title('Learning Curve(loss)')
ax[0].set_xlabel('Epochs')
ax[0].set_ylabel('Accuracy')
ax[0].legend(['train','Validation'], loc='best')
plt.show()

# model_pretrained=Pre_trained_model()

# model_pretrained.compile(
#     optimizer=optimizers.Adam(learning_rate=5e-5),
#     loss='binary_crossentropy',
#     metrics=['accuracy']
# )
# model_pretrained.summary()

# from tensorflow.keras.layers import MultiHeadAttention

# def self_attention_block(inputs):
#     # Multi-head self-attention layer
#     attention_output = MultiHeadAttention(num_heads=8, key_dim=inputs.shape[-1])(inputs, inputs)

#     # Add & Normalize
#     attention_output = layers.Add()([inputs, attention_output])
#     attention_output = layers.LayerNormalization()(attention_output)

#     return attention_output

# def Pre_trained_model_with_self_attention():
#     # Input shape = [width, height, color channels]
#     inputs = layers.Input(shape=(img_L, img_L, 3))

#     # Base model
#     x = base_model(inputs, training=False)

#     # GlobalAveragePooling
#     x = layers.GlobalAveragePooling2D()(x)

#     # Reshape for attention
#     x = layers.Reshape((-1, 128))(x)

#     # Add self-attention block
#     x = self_attention_block(x)

#     # Continue with dense layers
#     x = layers.Flatten()(x)
#     x = layers.Dense(128, activation='relu')(x)
#     x = layers.Dropout(0.3)(x)

#     # Final output layer
#     output = layers.Dense(1, activation='sigmoid')(x)

#     model = Model(inputs=[inputs], outputs=output)

#     return model

model_atten=Pre_trained_model_with_self_attention()
model_atten.compile(loss='binary_crossentropy'
              , optimizer =optimizers.Adam(learning_rate=5e-5), metrics=['binary_accuracy'])

model_atten.summary()

history_atten=model_atten.fit(
    train_generator,
    epochs=20,
    validation_data=val_generator,
    callbacks=[model_checkpoint_callback,Early_Stopping,reduce_lr]
)

# history_pretrained=model_pretrained.fit(
#     train_generator,
#     epochs=30,
#     validation_data=test_generator,
#     callbacks=[model_checkpoint_callback,Early_Stopping,reduce_lr]
# )

"""#Fune Tuning"""

base_model.trainable = True

# Freeze all layers except for the
for layer in base_model.layers[:-30]:
    layer.trainable = False

# model_pretrained.compile(
#                 loss='binary_crossentropy'
#               , optimizer =optimizers.Adam(learning_rate=0.000005)
#               , metrics=['binary_accuracy'])

# model_pretrained.summary()

# history_pretrained=model_pretrained.fit(
#     train_generator,
#     epochs=10,
#     validation_data=val_generator,
#     callbacks=[model_checkpoint_callback,Early_Stopping,reduce_lr]
# )

# model_pretrained.compile(
#     optimizer=optimizers.Adam(learning_rate=5e-5),
#     loss='binary_crossentropy',
#     metrics=['accuracy']
# )

for num_layer ,layer in enumerate(base_model.layers):
  print(num_layer,layer.name,layer.trainable)

history_pretrained=model_pretrained.fit(
    train_generator,
    epochs=30,
    validation_data=test_generator,
    callbacks=[model_checkpoint_callback,Early_Stopping,reduce_lr]
)

fig,ax = plt.subplots(1,2,figsize=(10,5))
sns.lineplot(x=history_pretrained.epoch,y=history_pretrained.history['accuracy'],ax=ax[0],label='train')
sns.lineplot(x=history_pretrained.epoch,y=history_pretrained.history['val_accuracy'],ax=ax[0],label='val')
ax[0].set_title('Learning Curve(loss)')
ax[0].set_xlabel('Epochs')
ax[0].set_ylabel('Accuracy')
ax[0].legend(['train','Validation'], loc='best')
plt.show()



# if os.path.exists('/content/val_data'):
#     # Loop through the folder and remove all files and directories
#     for filename in os.listdir('/content/val_data'):
#         file_path = os.path.join('/content/val_data', filename)
#         try:
#             if os.path.isfile(file_path) or os.path.islink(file_path):
#                 os.unlink(file_path)  # Remove the file
#             elif os.path.isdir(file_path):
#                 shutil.rmtree(file_path)  # Remove the directory
#         except Exception as e:
#             print(f"Failed to delete {file_path}. Reason: {e}")
# else:
#     print(f"The folder {'/content/val_data'} does not exist!")

# # Confirm that the folder is now empty
# print(f"Files in {'/content/val_data'} after cleaning:", os.listdir('/content/val_data'))

"""# ***Deployment***

"""

from huggingface_hub import notebook_login

notebook_login()

pip install transformers datasets

import os

# Create directory if it doesn't exist
os.makedirs('/content/saved_model', exist_ok=True)

# Save the model
model_get.save('/content/saved_model/my_model.keras')  # or use .h5



!huggingface-cli login

import os

model_path = '/content/saved_model/my_model.keras'  # Update with your model path
print(os.path.exists(model_path))  # Should return True if the model exists

import shutil

# Move the model file to the repository directory
shutil.move('/content/saved_model/my_model.h5', '/content/anaiss2/Pro-Food/my_model.h5')  # Adjust based on the file you want to move

from huggingface_hub import Repository

model_name = "anaiss2/Pro-Food"  # Your repository name
repo = Repository(model_name)  # Create the repository instance

# Add the model file from the repository directory
repo.git_add("my_model.h5")  # or "my_model.keras"

# Commit the changes
repo.git_commit("Add model file")

# Push to the Hugging Face Hub
repo.git_push()

pip install huggingface_hub transformers datasets

from huggingface_hub import notebook_login

notebook_login()

pip install gradio

import gradio as gr
import tensorflow as tf
import numpy as np
from PIL import Image

# Load model
model = tf.keras.models.load_model('/content/chest-xray-classifier/my_model.h5')

# Define prediction function
def predict(image):
    image = image.resize((224, 224))
    image = np.array(image) / 255.0
    image = np.expand_dims(image, axis=0)
    prediction = model.predict(image)
    return "Pneumonia" if prediction[0] > 0.5 else "Normal"

# Gradio interface
gr.Interface(fn=predict, inputs=gr.inputs.Image(), outputs="label").launch()

git clone https://huggingface.co/spaces/nadaaaaaaaaaaaaaaaaaaaa/nada_rahma_zeinab_alaa

import gradio as gr

def greet(name):
    return "Hello " + name + "!!"

demo = gr.Interface(fn=greet, inputs="text", outputs="text")
demo.launch()

git add app.py


git commit -m "Add application file"


git push